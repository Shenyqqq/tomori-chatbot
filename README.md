[ä¸­æ–‡](https://github.com/Shenyqqq/tomori-chatbot/blob/master/README.zh.md)[English](https://github.com/Shenyqqq/tomori-chatbot/blob/master/README.md)
# tomori-chatbot

An AI chatbot designed to simulate the character Takamatsu Tomori from *BanG Dream\! It's MyGO\!\!\!\!\!*.

The project integrates a LoRA-tuned large language model with a Retrieval-Augmented Generation (RAG) system for context-aware responses. The front end is a Gradio web UI which features a Live2D model whose expressions are dynamically controlled by the language model's output.

-----

## Features

  * **Character-Specific Dialogue**: Generates text in the persona of a specific character using a LoRA-finetuned Qwen2.5-7B-Instruct-GPTQ-Int4 model.
  * **Retrieval-Augmented Generation (RAG)**: Enhances responses with relevant context by retrieving information from a vector knowledge base before generation.
  * **Dynamic Live2D Expressions**: Parses the generated text to determine an emotional sentiment, which then triggers the corresponding animation in a Live2D model rendered on the web UI.
  * **Web Interface**: Built with Gradio for straightforward user interaction and demonstration.

## Demo

[Bilibili](https://www.bilibili.com/video/BV1AU39zzESa/)
![alt text](https://github.com/Shenyqqq/tomori-chatbot/blob/master/static/demo.gif)


## System Architecture

The application operates on the following data flow:

*(A simple block diagram is recommended to visualize this flow.)*

1.  **Input**: The user submits a text string through the Gradio web interface.
2.  **Retrieval**: The input string is converted to an embedding and used to perform a similarity search against a pre-built vector database (ChromaDB). The top-k results are retrieved as context.
3.  **Prompt Construction**: A final prompt is assembled using a template that includes the system persona, the retrieved context, and the user's original input.
4.  **Generation**: The constructed prompt is passed to the Qwen2.5-7B model with the attached LoRA adapter. The model generates the response text.
5.  **Sentiment Analysis**: The generated text is processed by a lightweight function (e.g., keyword-based classifier) to map it to a predefined emotion category (e.g., `neutral`, `happy`, `sad`).
6.  **Output**: The generated text and the emotion category are sent back to the Gradio frontend. The text is displayed in the chat log, and the emotion category is used by a JavaScript listener to trigger the appropriate Live2D expression.

## Technology Stack

  * **LLM**: `Qwen2.5-7B-Instruct-GPTQ-Int4`
  * **Fine-tuning**: `LoRA (Low-Rank Adaptation)`
  * **Backend**: `Python`, `Gradio`
  * **Frontend**: `HTML`, `JavaScript`
  * **Animation**: `Live2D Cubism SDK for Web`
  * **RAG**: Vector database library based on `ChromaDB`.

## Data and Fine-tuning

The model's performance relies on a multi-source dataset strategy for both fine-tuning and retrieval.

### Fine-tuning Data

The LoRA adapter was trained on a composite dataset:

1.  **Game Scripts**: Base dialogue extracted directly from game data files. This provided the foundational character persona but was insufficient in volume and conversational quality.
2.  **LLM-Augmented QA**: A large set of question-answer pairs generated by an auxiliary LLM. This was created to expand the dataset, improve conversational flow, and mitigate the limitations of the original script data.
3.  **General Dialogue Data**: A small, curated set of generic conversational data was included to improve the model's generalization and prevent overfitting.

### RAG Knowledge Base

For efficiency, the **LLM-Augmented QA dataset** was repurposed as the knowledge base for the RAG system. This approach ensures that the retrieved context is stylistically consistent with the fine-tuned model's expected output.

## Setup and Installation

1.  **Clone the repository:**

    ```bash
    git clone https://github.com/Shenyqqq/tomori-chatbot.git
    cd tomori-chatbot
    ```

2.  **Create a Python virtual environment and install dependencies:**

    ```bash
    # It is recommended to use a virtual environment
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124
    pip install -r requirements.txt
    ```

3.  **Run the application:**

You have to download the lora model from [ðŸ¤—hugging face model](https://huggingface.co/gumigumi/qwen2.5-7B-Int4-tomori_lora) named `checkpoint-70`
Put the `checkpoint-70` on dir `lora_model`.

    First build a vector DB
   
    ```bash
    python build_VecDB.py
    ```
    
    Then run the app.py
    
     ```bash
    python app.py
    ```

    The web interface will be available at `http://127.0.0.1:7860`.

    Or extract the release .zip file. Then run the setup.bat to build the environment, and run start.bat to launch the chatbot.

## Future Development

  * **TTS Integration**: Implement a Text-to-Speech model for voice output, basically using GPT-Sovits.
  * **Choice of live2D model**: Add a button to select different live2d model.
  * **Other character lora-finetuned**: Create other character chatbot in bangdream.
